{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1009e-01,  9.2717e-02, -2.7462e-02, -3.1071e-01, -1.0717e-01,\n",
       "         -2.3865e-01,  6.0450e-02,  3.8751e-02, -1.4864e-05,  2.0225e-01],\n",
       "        [ 4.5657e-02,  4.1685e-02,  6.0646e-02, -2.3540e-01, -2.1767e-01,\n",
       "         -1.8146e-01,  9.4981e-02,  1.6363e-01, -4.2947e-02,  2.2788e-01]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "X = torch.rand(size=(2, 20))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2093, -0.0867, -0.0293,  0.0773,  0.0816, -0.0660, -0.1818, -0.1548,\n",
       "         -0.0919,  0.0189],\n",
       "        [ 0.1275, -0.0321, -0.0359,  0.2135,  0.1290,  0.0024, -0.2289, -0.0568,\n",
       "         -0.0428, -0.0532]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.out = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X))) \n",
    "\n",
    "net = MLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySequential(\n",
      "  (zhx0zhx): Linear(in_features=20, out_features=256, bias=True)\n",
      "  (zhx1zhx): ReLU()\n",
      "  (zhx2zhx): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "OrderedDict([('zhx0zhx.weight', tensor([[-0.1972, -0.0679,  0.2108,  ...,  0.0641,  0.0685,  0.0042],\n",
      "        [-0.0051, -0.1091,  0.1752,  ...,  0.1591,  0.0496,  0.0805],\n",
      "        [ 0.2116,  0.0739, -0.0511,  ..., -0.1658,  0.0035,  0.0312],\n",
      "        ...,\n",
      "        [ 0.2128, -0.1436, -0.0048,  ...,  0.1962,  0.0796, -0.1639],\n",
      "        [-0.1459,  0.1434,  0.0642,  ..., -0.0586, -0.0203, -0.0533],\n",
      "        [ 0.0181,  0.1846,  0.0326,  ..., -0.1461,  0.0095, -0.1848]])), ('zhx0zhx.bias', tensor([-0.1488,  0.1981, -0.0441, -0.1765, -0.1587, -0.0113,  0.0501,  0.2136,\n",
      "        -0.0981,  0.0414,  0.0195, -0.0412, -0.0128, -0.0329,  0.0310, -0.0805,\n",
      "        -0.0257,  0.0020, -0.0891,  0.1313,  0.1872, -0.1374,  0.1126, -0.1961,\n",
      "        -0.1184, -0.0515,  0.1772, -0.0042,  0.0453,  0.1147, -0.2032, -0.0024,\n",
      "         0.0186,  0.2095, -0.1307,  0.0687,  0.2023, -0.1382, -0.1893, -0.1265,\n",
      "         0.0246,  0.0715,  0.0561, -0.1465, -0.0844,  0.2065, -0.0542,  0.1169,\n",
      "        -0.2092, -0.1156,  0.1388,  0.0602, -0.1685,  0.0671,  0.0088,  0.0428,\n",
      "         0.0214,  0.0144, -0.1704, -0.0086,  0.0301, -0.0525,  0.1188,  0.0199,\n",
      "         0.1744,  0.1370, -0.1231,  0.2027,  0.0899,  0.0370,  0.1055,  0.1534,\n",
      "         0.1300, -0.0205, -0.0555, -0.0548, -0.1845,  0.0421, -0.0811, -0.1711,\n",
      "        -0.2099, -0.1824,  0.1126,  0.0480,  0.1724, -0.0070, -0.0638, -0.1225,\n",
      "         0.0744, -0.1853, -0.0934, -0.1688,  0.2217,  0.0114, -0.0799,  0.1014,\n",
      "         0.1339, -0.0363,  0.1866,  0.0193,  0.1464,  0.2138, -0.0714,  0.0953,\n",
      "         0.0421, -0.1623,  0.1136,  0.0295, -0.0459,  0.1052,  0.0971, -0.1367,\n",
      "         0.0165,  0.0716, -0.1584, -0.1162, -0.0906,  0.1709, -0.0782,  0.0397,\n",
      "         0.0773,  0.1782,  0.1232,  0.1642,  0.1518,  0.2178, -0.0435, -0.0799,\n",
      "        -0.0469,  0.0028, -0.1698, -0.1061, -0.1184, -0.1063,  0.1714, -0.0816,\n",
      "         0.0551,  0.1410,  0.1969,  0.1340, -0.0529,  0.0489, -0.0331,  0.0857,\n",
      "         0.1818, -0.1441, -0.0098, -0.1433, -0.0611,  0.0384, -0.0159, -0.1821,\n",
      "         0.0323, -0.2090,  0.2057,  0.2039, -0.0012,  0.0976, -0.0365,  0.0620,\n",
      "        -0.1975, -0.2185,  0.1347, -0.1319, -0.0196,  0.1976, -0.1070, -0.0914,\n",
      "        -0.0406,  0.0333,  0.1858, -0.2074, -0.1178, -0.1217,  0.1725, -0.0196,\n",
      "        -0.1807,  0.1671,  0.0338,  0.0962, -0.1049, -0.1927,  0.1820,  0.1644,\n",
      "         0.2118, -0.0361,  0.1239, -0.0028, -0.1339, -0.1235, -0.1615, -0.0867,\n",
      "        -0.0575, -0.0837,  0.0049,  0.1440,  0.1971,  0.0522,  0.0424, -0.0205,\n",
      "         0.0700, -0.1890, -0.2231,  0.1711,  0.0450, -0.0780, -0.1755, -0.0385,\n",
      "        -0.0104, -0.0761, -0.1308, -0.1800,  0.1979,  0.0880,  0.1720, -0.1390,\n",
      "         0.0460, -0.1717, -0.0428,  0.0955,  0.0538,  0.2212,  0.0707, -0.2178,\n",
      "        -0.2021, -0.0303, -0.0838, -0.1628,  0.1811, -0.0716, -0.0476,  0.0670,\n",
      "         0.1689, -0.2174,  0.1512, -0.0020, -0.1556, -0.2056,  0.0268,  0.0314,\n",
      "         0.0208,  0.0968, -0.0060,  0.0573, -0.0877,  0.1767, -0.1658, -0.1167,\n",
      "        -0.0321,  0.1288, -0.0375, -0.0035,  0.1596, -0.0052,  0.0229,  0.1809])), ('zhx2zhx.weight', tensor([[ 0.0017, -0.0184, -0.0137,  ..., -0.0542,  0.0158,  0.0526],\n",
      "        [-0.0090, -0.0538,  0.0204,  ..., -0.0153,  0.0380, -0.0200],\n",
      "        [-0.0031, -0.0337, -0.0359,  ..., -0.0191, -0.0483,  0.0255],\n",
      "        ...,\n",
      "        [ 0.0188,  0.0188,  0.0051,  ..., -0.0291,  0.0089, -0.0327],\n",
      "        [-0.0256, -0.0366, -0.0042,  ..., -0.0178, -0.0076,  0.0077],\n",
      "        [-0.0408, -0.0415,  0.0332,  ..., -0.0482,  0.0126, -0.0331]])), ('zhx2zhx.bias', tensor([ 0.0257, -0.0360,  0.0480,  0.0247,  0.0186,  0.0135, -0.0279, -0.0147,\n",
      "        -0.0219, -0.0238]))])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1185, -0.1768,  0.1484,  0.1791, -0.0622,  0.1661, -0.0674,  0.0157,\n",
       "         -0.0850, -0.0673],\n",
       "        [-0.0541, -0.0632,  0.1574,  0.1301,  0.0108,  0.1929, -0.1207,  0.0157,\n",
       "         -0.0308, -0.1161]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for i, block in enumerate(args):\n",
    "            self.add_module(''.join(['zhx', str(i), 'zhx']), block)\n",
    "            # self._modules[i] = block\n",
    "            # print(self._modules)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # print(self._modules)\n",
    "        # print(self._modules.keys())\n",
    "        # print(self._modules.values())\n",
    "        # print(self._modules.items())\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X\n",
    "\n",
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "print(net)\n",
    "print(net.state_dict())\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fa4b62426a0cdf1c02e81afc6355f8e9b3dd70393a728624f053bfcdc4160eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
