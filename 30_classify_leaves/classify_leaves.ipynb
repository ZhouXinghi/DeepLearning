{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = pd.read_csv('data/classify-leaves/train.csv')\n",
    "n_train = int(len(csv_data) * 0.8)\n",
    "n_valid = len(csv_data) - n_train\n",
    "print(n_train)\n",
    "#  print(csv_data.head(5))\n",
    "#  print(csv_data.describe())\n",
    "#  print(len(csv_data))\n",
    "#  print(csv_data.iloc[6, 0], csv_data.iloc[6, 1])\n",
    "\n",
    "#  def barw(ax):\n",
    "#      for p in ax.patches:\n",
    "#          val = p.get_width()\n",
    "#          x = p.get_x() + p.get_width()\n",
    "#          y = p.get_y() + p.get_height() / 2\n",
    "#          ax.annotate(round(val, 2), (x, y))\n",
    "#\n",
    "#  plt.figure(figsize=(15, 30))\n",
    "#  ax0 = sns.countplot(y=labels_data_frame['label'], order=labels_data_frame['label'].value_counts().index)\n",
    "#  barw(ax0)\n",
    "#  plt.show()\n",
    "\n",
    "leaves_labels = sorted(list(set(csv_data['label'])))\n",
    "n_classes = len(leaves_labels)\n",
    "#  print(n_classes)\n",
    "#  print(leaves_labels[:10])\n",
    "\n",
    "#  class_to_num = { c: l for (c, l) in zip(leaves_labels, range(n_classes)) }\n",
    "class_to_num = { label: i for (i, label) in enumerate(leaves_labels) }\n",
    "#  print(len(class_to_num))\n",
    "#  for i, item in enumerate(class_to_num.items()):\n",
    "#      print(item)\n",
    "#      if i == 10:\n",
    "#          break\n",
    "\n",
    "num_to_class = { i: label for (i, label) in enumerate(leaves_labels) }\n",
    "#  print(len(num_to_class))\n",
    "#  for i, item in enumerate(class_to_num.items()):\n",
    "#      print(item)\n",
    "#      if i == 10:\n",
    "#          break\n",
    "\n",
    "class LeavesData(data.Dataset):\n",
    "    def __init__(self, csv_path, img_dir):\n",
    "        self.img_dir = img_dir\n",
    "        self.csv_data = pd.read_csv(csv_path)\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_dir, self.csv_data.iloc[index, 0])\n",
    "        \n",
    "        image = transforms.ToTensor()(Image.open(img_path))\n",
    "        #  image = read_image(img_path)\n",
    "        #  image.dtype = torch.float32\n",
    "        label = self.csv_data.iloc[index, 1]\n",
    "        return image, label\n",
    "    def __len__(self):\n",
    "        return len(self.csv_data)\n",
    "\n",
    "all_dataset = LeavesData('data/classify-leaves/train.csv', 'data/classify-leaves')\n",
    "train_dataset, valid_dataset = data.random_split(all_dataset, [n_train, n_valid])\n",
    "#  print(len(train_dataset), len(valid_dataset), len(all_dataset))\n",
    "\n",
    "#  img, label = train_dataset[0]\n",
    "#  print(img.size())\n",
    "#  transforms.ToPILImage()(img).show()\n",
    "#  print(label)\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "valid_loader = data.DataLoader(valid_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "#  for i, (X, y) in enumerate(train_loader):\n",
    "#      for j in range(X.shape[0]):\n",
    "#          transforms.ToPILImage()(X[j]).show()\n",
    "#          print(y[j])\n",
    "#      if i == 0:\n",
    "#          break\n",
    "\n",
    "net = models.resnet34()\n",
    "net.fc.out_features = n_classes\n",
    "#  print(net.fc)\n",
    "#  print(net)\n",
    "#  for i, (X, y) in enumerate(train_loader):\n",
    "    #  print(X)\n",
    "    #  print(net(X).size())\n",
    "    #  print(y)\n",
    "    #  break\n",
    "#  X = next(iter(train_loader))\n",
    "#  print(X.size())\n",
    "#  X = net(X)\n",
    "#  print(X.size())\n",
    "#  print(net)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01, weight_decay=0.001)\n",
    "num_epochs = 20\n",
    "\n",
    "import d2l.torch as d2l\n",
    "d2l.train_ch6()\n",
    "\n",
    "model_path = './pre_res_model.ckpt'\n",
    "def train_model(net, train_loader, valid_loader, loss, num_epochs, optimizer, device):\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        # train\n",
    "        net.train()\n",
    "        train_loss_list = []\n",
    "        train_acc_list = []\n",
    "        for i_batch, (X, y) in enumerate(train_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
    "            train_loss_list.append(loss.item())\n",
    "            train_acc_list.append(acc)\n",
    "        train_loss = sum(train_loss_list) / len(train_loss_list)\n",
    "        train_acc = sum(train_acc_list) / len(train_acc_list)\n",
    "        print(f'[ Train | epoch{epoch + 1}/{num_epochs} ]\\ttrain_loss:{train_loss:.5f}, train_acc:{train_acc:.5f}')\n",
    "\n",
    "        # validation\n",
    "        net.eval()\n",
    "        valid_loss_list = []\n",
    "        valid_acc_list = []\n",
    "        for i_batch, (X, y) in enumerate(valid_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            acc = (y_hat.argmax(dim=1) == y).float().mean()\n",
    "            valid_loss_list.append(loss.item())\n",
    "            valid_acc_list.append(acc)\n",
    "        valid_loss = sum(valid_loss_list) / len(valid_loss_list)\n",
    "        valid_acc = sum(valid_acc_list) / len(valid_acc_list)\n",
    "        print(f'[ Valid | epoch{epoch + 1}/{num_epochs} ]\\tvalid_loss:{valid_loss:.5f}, valid_acc:{valid_acc:.5f}')\n",
    "\n",
    "        if valid_acc > best_acc:\n",
    "            best_acc = valid_acc\n",
    "            torch.save(net.state_dict(), model_path)\n",
    "            print(f'saving model with acc {best_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(net, train_loader, valid_loader, loss, num_epochs, optimizer, device=torch.device('cuda:0'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13 (main, Oct 13 2022, 21:15:33) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fa4b62426a0cdf1c02e81afc6355f8e9b3dd70393a728624f053bfcdc4160eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
